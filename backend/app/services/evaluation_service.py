"""
Evaluation service using Google Gemini API
ë¬¸ë²• ë° í‘œí˜„ í”¼ë“œë°± ì „ë‹´ (ë°œìŒ í‰ê°€ëŠ” Azureì—ì„œ ì²˜ë¦¬)
"""
import json
from typing import Optional, Any
import google.generativeai as genai  # type: ignore
from app.config import get_settings

settings = get_settings()


class EvaluationService:
    """ë¬¸ë²• ë° í‘œí˜„ í”¼ë“œë°± ìƒì„± ì„œë¹„ìŠ¤"""
    
    def __init__(self):
        """Initialize evaluation service"""
        self.api_key = settings.gemini_api_key
        self.model: Optional[Any] = None  # type: ignore
        
        print(f"[DEBUG] Gemini API Key present: {bool(self.api_key)}")
        
        if self.api_key:
            try:
                genai.configure(api_key=self.api_key)  # type: ignore
                self.model = genai.GenerativeModel("gemini-2.0-flash")  # type: ignore
                print(f"[DEBUG] Gemini model initialized: {self.model}")
                print("Gemini API initialized for evaluation")
            except Exception as e:
                print(f"Warning: Gemini API initialization failed: {str(e)}")
                import traceback
                traceback.print_exc()
                self.model = None
        else:
            print("[WARNING] No Gemini API key found - using mock responses")
    
    async def evaluate_grammar_and_expression(
        self,
        corrected_text: str,
        scenario_context: str,
        raw_text: str = ""
    ) -> dict:
        """
        ë³´ì •ëœ í…ìŠ¤íŠ¸ì— ëŒ€í•œ ë¬¸ë²• ë° í‘œí˜„ í‰ê°€
        
        Args:
            corrected_text: ë³´ì •ëœ ì¼ë³¸ì–´ í…ìŠ¤íŠ¸
            scenario_context: ì‹œë‚˜ë¦¬ì˜¤ ìƒí™©
            raw_text: ì›ë³¸ STT í…ìŠ¤íŠ¸ (êµì • ì „)
            
        Returns:
            dict: {
                "grammar_score": 85,
                "grammar_feedback": "ë¬¸ë²•ì ìœ¼ë¡œ ì •í™•í•©ë‹ˆë‹¤",
                "appropriateness_score": 90,
                "appropriateness_feedback": "ìƒí™©ì— ë§¤ìš° ì ì ˆí•©ë‹ˆë‹¤",
                "better_expressions": ["ë” ì¢‹ì€ í‘œí˜„ 1", "ë” ì¢‹ì€ í‘œí˜„ 2"],
                "coaching_advice": "í•œêµ­ì–´ ì½”ì¹­ ì¡°ì–¸"
            }
        """
        if self.model is None:
            return self._create_mock_grammar_evaluation()
        
        model = self.model
        
        try:
            prompt = self._create_grammar_evaluation_prompt(
                corrected_text,
                scenario_context,
                raw_text
            )
            
            generation_config = genai.types.GenerationConfig(  # type: ignore
                temperature=0.3,
                top_p=0.95,
                top_k=40,
                max_output_tokens=512,
            )
            
            response = await model.generate_content_async(
                prompt,
                generation_config=generation_config
            )
            
            # ì‘ë‹µ ê²€ì¦ - ë””ë²„ê¹… ë¡œê·¸ ì¶”ê°€
            print(f"[DEBUG] Gemini Response received")
            
            if not response.candidates or len(response.candidates) == 0:
                print("Warning: No candidates in Gemini grammar evaluation")
                return self._create_mock_grammar_evaluation()
            
            candidate = response.candidates[0]
            print(f"[DEBUG] finish_reason: {candidate.finish_reason} (type: {type(candidate.finish_reason)})")
            
            # finish_reason ì²´í¬ ì™„í™” (STOP=1 ì™¸ì—ë„ ë‹¤ë¥¸ ì •ìƒ ì™„ë£Œ ê°’ í—ˆìš©)
            # Gemini 2.5ì—ì„œëŠ” finish_reasonì´ ë‹¤ë¥¼ ìˆ˜ ìˆìŒ
            if hasattr(candidate.finish_reason, 'name'):
                finish_reason_name = candidate.finish_reason.name
                print(f"[DEBUG] finish_reason name: {finish_reason_name}")
                if finish_reason_name not in ['STOP', 'MAX_TOKENS']:
                    print(f"Warning: Gemini grammar evaluation finish_reason={finish_reason_name}")
                    return self._create_mock_grammar_evaluation()
            elif candidate.finish_reason not in [1, 2]:  # 1=STOP, 2=MAX_TOKENS
                print(f"Warning: Gemini grammar evaluation finish_reason={candidate.finish_reason}")
                return self._create_mock_grammar_evaluation()
            
            if not hasattr(response, 'text') or not response.text:
                print("Warning: No text in Gemini grammar evaluation")
                print(f"[DEBUG] response attributes: {dir(response)}")
                return self._create_mock_grammar_evaluation()
            
            response_text = response.text.strip()
            print(f"[DEBUG] Raw response text: {response_text[:200]}...")
            
            # JSON ì¶”ì¶œ
            if "```json" in response_text:
                json_start = response_text.find("```json") + 7
                json_end = response_text.find("```", json_start)
                response_text = response_text[json_start:json_end].strip()
            elif "```" in response_text:
                json_start = response_text.find("```") + 3
                json_end = response_text.find("```", json_start)
                response_text = response_text[json_start:json_end].strip()
            
            result = json.loads(response_text)
            
            print(f"Grammar Evaluation Result: {result}")
            
            return {
                "grammar_score": result.get("grammar_score", 85),
                "grammar_feedback": result.get("grammar_feedback", ""),
                "appropriateness_score": result.get("appropriateness_score", 90),
                "appropriateness_feedback": result.get("appropriateness_feedback", ""),
                "better_expressions": result.get("better_expressions", []),
                "coaching_advice": result.get("coaching_advice", "")
            }
            
        except Exception as e:
            print(f"Grammar Evaluation Error: {str(e)}")
            import traceback
            traceback.print_exc()
            return self._create_mock_grammar_evaluation()
    
    def _create_grammar_evaluation_prompt(
        self,
        corrected_text: str,
        scenario_context: str,
        raw_text: str = ""
    ) -> str:
        """ë¬¸ë²• ë° í‘œí˜„ í‰ê°€ í”„ë¡¬í”„íŠ¸ ìƒì„±"""
        raw_text_info = f"""
**ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®å®Ÿéš›ã®ç™ºè¨€ï¼ˆSTTåŸæ–‡ï¼‰:**
{raw_text}
""" if raw_text else ""
        
        return f"""ã‚ãªãŸã¯å„ªã—ãå³æ ¼ãªæ—¥æœ¬èªã‚³ãƒ¼ãƒã§ã™ã€‚å­¦ç¿’è€…ãŒæˆé•·ã§ãã‚‹ã‚ˆã†ã€å…·ä½“çš„ã§å®Ÿè·µçš„ãªã‚¢ãƒ‰ãƒã‚¤ã‚¹ã‚’ã—ã¦ãã ã•ã„ã€‚

**çŠ¶æ³ï¼ˆã‚·ãƒŠãƒªã‚ªï¼‰:**
{scenario_context}
{raw_text_info}
**ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®ç™ºè¨€ï¼ˆè£œæ­£æ¸ˆã¿ï¼‰:**
{corrected_text}

**è©•ä¾¡é …ç›®:**
1. æ–‡æ³•ã®æ­£ç¢ºæ€§ï¼ˆ0-100ç‚¹ï¼‰
2. çŠ¶æ³ã¸ã®é©åˆ‡æ€§ï¼ˆTPOã€0-100ç‚¹ï¼‰
3. ã‚ˆã‚Šè‰¯ã„è¡¨ç¾ã®ææ¡ˆ
4. **éŸ“å›½èªã‚³ãƒ¼ãƒãƒ³ã‚°ã‚¢ãƒ‰ãƒã‚¤ã‚¹ï¼ˆå¿…é ˆï¼‰**

**ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯åŸå‰‡:**
- 80ç‚¹ä»¥ä¸‹: å…·ä½“çš„ãªèª¤ã‚Šã‚„æ”¹å–„ç‚¹ã‚’æ˜ç¤º
- 81-89ç‚¹: æ”¹å–„ã§ãã‚‹å…·ä½“çš„ãªãƒã‚¤ãƒ³ãƒˆã‚’æç¤º
- 90-95ç‚¹: ã•ã‚‰ã«æ´—ç·´ã§ãã‚‹ç‚¹ã‚’ææ¡ˆ
- 96-100ç‚¹ã®ã¿: "æ–‡æ³•çš„ã«æ­£ç¢ºã§ã™" ã¾ãŸã¯ "çŠ¶æ³ã«é©åˆ‡ã§ã™"

**ã‚³ãƒ¼ãƒãƒ³ã‚°ã‚¢ãƒ‰ãƒã‚¤ã‚¹ä½œæˆãƒ«ãƒ¼ãƒ«ï¼ˆéŸ“å›½èªã§ä½œæˆï¼‰:**
1. å…·ä½“çš„ãªèª¤ã‚Šã‚’æŒ‡æ‘˜ (ä¾‹: "å·¦å³"ã¯"è²¡å¸ƒ"ã®èª¤èªè­˜)
2. ãªãœèª¤ã£ãŸã®ã‹èª¬æ˜ (ä¾‹: éŸ³å£°èªè­˜ã®åŒéŸ³ç•°ç¾©èªãƒŸã‚¹)
3. æ­£ã—ã„è¡¨ç¾ã¨ä½¿ã„æ–¹ã‚’æ•™ãˆã‚‹ (ä¾‹: "è²¡å¸ƒã‚’ãªãã—ã¾ã—ãŸ"ãŒè‡ªç„¶)
4. ãƒ™ã‚¹ãƒˆãƒ—ãƒ©ã‚¯ãƒ†ã‚£ã‚¹æç¤º (ä¾‹: "è²¡å¸ƒã‚’ç´›å¤±ã—ã¾ã—ãŸã€‚å±Šã‘å‡ºã‚’ãŠé¡˜ã„ã—ã¾ã™ã€‚")
5. åŠ±ã¾ã—ã®è¨€è‘‰ã§ç· ã‚ããã‚‹ (ä¾‹: "æ¬¡ã¯ã‚‚ã£ã¨è‰¯ããªã‚Šã¾ã™ã‚ˆï¼")

**ã‚³ãƒ¼ãƒãƒ³ã‚°ä¾‹:**
"ì¢‹ì€ ì‹œë„ì˜ˆìš”! ë‹¤ë§Œ 'å·¦å³(ì‚¬ìœ )'ëŠ” 'è²¡å¸ƒ(ì‚¬ì´í›„, ì§€ê°‘)'ì˜ ìŒì„± ì¸ì‹ ì˜¤ë¥˜ì…ë‹ˆë‹¤. ì´ ìƒí™©ì—ì„œëŠ” 'è²¡å¸ƒã‚’ãªãã—ã¦ã—ã¾ã„ã¾ã—ãŸ'ë¼ê³  ë§í•˜ëŠ” ê²ƒì´ ìì—°ìŠ¤ëŸ¬ì›Œìš”. ë” ê²©ì‹ìˆê²ŒëŠ” 'è²¡å¸ƒã‚’ç´›å¤±ã—ã¾ã—ãŸã€‚å±Šã‘å‡ºã‚’ãŠé¡˜ã„ã—ã¾ã™ã€‚'ë¼ê³  í‘œí˜„í•˜ë©´ ì™„ë²½í•©ë‹ˆë‹¤! ë‹¤ìŒì—” ë” ì˜í•˜ì‹¤ ê±°ì˜ˆìš” ğŸ’ª"

**å‡ºåŠ›å½¢å¼ï¼ˆJSONã®ã¿ï¼‰:**
{{
    "grammar_score": ç‚¹æ•°,
    "grammar_feedback": "æ–‡æ³•è©•ä¾¡ï¼ˆå…·ä½“çš„æ”¹å–„ç‚¹ã€30æ–‡å­—ä»¥å†…ï¼‰",
    "appropriateness_score": ç‚¹æ•°,
    "appropriateness_feedback": "TPOè©•ä¾¡ï¼ˆå…·ä½“çš„æ”¹å–„ç‚¹ã€30æ–‡å­—ä»¥å†…ï¼‰",
    "better_expressions": ["ã‚ˆã‚Šè‡ªç„¶ãªè¡¨ç¾1", "ã‚ˆã‚Šä¸å¯§ãªè¡¨ç¾2"],
    "coaching_advice": "éŸ“å›½èªã§200-300æ–‡å­—ã®å…·ä½“çš„ã‚³ãƒ¼ãƒãƒ³ã‚°ï¼ˆå¿…ãšä¸Šè¨˜ãƒ«ãƒ¼ãƒ«ã«å¾“ã†ï¼‰"
}}

**é‡è¦:** èª¬æ˜ä¸è¦ã€‚JSONå½¢å¼ã®ã¿å‡ºåŠ›ã—ã¦ãã ã•ã„ã€‚coaching_adviceã¯å¿…é ˆã§ã™ã€‚"""
    
    def _create_mock_grammar_evaluation(self) -> dict:
        """Mock ë¬¸ë²• í‰ê°€ ê²°ê³¼"""
        return {
            "grammar_score": 88,
            "grammar_feedback": "æ–‡æ³•çš„ã«æ­£ç¢ºã§ã™",
            "appropriateness_score": 92,
            "appropriateness_feedback": "çŠ¶æ³ã«éå¸¸ã«é©åˆ‡ã§ã™",
            "better_expressions": [
                "è²¡å¸ƒã‚’ç´›å¤±ã—ã¾ã—ãŸã€‚å±Šã‘å‡ºã‚’ãŠé¡˜ã„ã—ã¾ã™ã€‚",
                "è²¡å¸ƒã‚’ãªãã—ã¦ã—ã¾ã„ã¾ã—ãŸã€‚éºå¤±ç‰©ã¨ã—ã¦å±Šã‘ãŸã„ã®ã§ã™ãŒã€‚"
            ],
            "coaching_advice": "ì¢‹ì€ ì‹œë„ì˜ˆìš”! ì „ì²´ì ìœ¼ë¡œ ìì—°ìŠ¤ëŸ¬ìš´ í‘œí˜„ì´ì§€ë§Œ, ë” ê²©ì‹ìˆê²ŒëŠ” 'è²¡å¸ƒã‚’ç´›å¤±ã—ã¾ã—ãŸã€‚å±Šã‘å‡ºã‚’ãŠé¡˜ã„ã—ã¾ã™ã€‚'ë¼ê³  í‘œí˜„í•˜ë©´ ì™„ë²½í•©ë‹ˆë‹¤! ê³„ì† ì—°ìŠµí•˜ì‹œë©´ ë” ì˜í•˜ì‹¤ ê±°ì˜ˆìš” ğŸ’ª"
        }
    
    async def generate_ai_response(
        self,
        corrected_text: str,
        scenario_context: str,
        overall_score: int
    ) -> str:
        """
        AI ìºë¦­í„°ì˜ ì‘ë‹µ ìƒì„±
        
        Args:
            corrected_text: ë³´ì •ëœ í…ìŠ¤íŠ¸
            scenario_context: ì‹œë‚˜ë¦¬ì˜¤ ìƒí™©
            overall_score: ì „ì²´ ì ìˆ˜
            
        Returns:
            str: AI ìºë¦­í„°ì˜ ì‘ë‹µ ëŒ€ì‚¬
        """
        if self.model is None:
            return "ã‚ã‹ã‚Šã¾ã—ãŸã€‚è©³ã—ããŠè©±ã‚’èã‹ã›ã¦ãã ã•ã„ã€‚"
        
        model = self.model
        
        try:
            prompt = f"""ã‚ãªãŸã¯è¦ªåˆ‡ãªæ—¥æœ¬äººã®ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼ã§ã™ã€‚

**çŠ¶æ³:**
{scenario_context}

**ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®ç™ºè¨€:**
{corrected_text}

**æŒ‡ç¤º:**
ä¸Šè¨˜ã®çŠ¶æ³ã§ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®ç™ºè¨€ã«å¯¾ã—ã¦è‡ªç„¶ã§åŠ©ã‘ã«ãªã‚‹æ—¥æœ¬èªã§å¿œç­”ã—ã¦ãã ã•ã„ã€‚
1æ–‡ã ã‘ã§ã€èª¬æ˜ã‚„å¼•ç”¨ç¬¦ã¯ä¸è¦ã§ã™ã€‚

å¿œç­”:"""
            
            generation_config = genai.types.GenerationConfig(  # type: ignore
                temperature=0.7,
                top_p=0.95,
                top_k=40,
                max_output_tokens=100,
            )
            
            response = await model.generate_content_async(
                prompt,
                generation_config=generation_config
            )
            
            # ì‘ë‹µ ê²€ì¦ - ë””ë²„ê¹… ë¡œê·¸ ì¶”ê°€
            print(f"[DEBUG] AI Response - Gemini Response received")
            
            if not response.candidates or len(response.candidates) == 0:
                print("Warning: No candidates in AI response")
                return "ã‚ã‹ã‚Šã¾ã—ãŸã€‚è©³ã—ããŠè©±ã‚’èã‹ã›ã¦ãã ã•ã„ã€‚"
            
            candidate = response.candidates[0]
            print(f"[DEBUG] AI Response finish_reason: {candidate.finish_reason}")
            
            # finish_reason ì²´í¬ ì™„í™”
            if hasattr(candidate.finish_reason, 'name'):
                finish_reason_name = candidate.finish_reason.name
                if finish_reason_name not in ['STOP', 'MAX_TOKENS']:
                    print(f"Warning: AI response finish_reason={finish_reason_name}")
                    return "ã‚ã‹ã‚Šã¾ã—ãŸã€‚è©³ã—ããŠè©±ã‚’èã‹ã›ã¦ãã ã•ã„ã€‚"
            elif candidate.finish_reason not in [1, 2]:
                print(f"Warning: AI response finish_reason={candidate.finish_reason}")
                return "ã‚ã‹ã‚Šã¾ã—ãŸã€‚è©³ã—ããŠè©±ã‚’èã‹ã›ã¦ãã ã•ã„ã€‚"
            
            if not hasattr(response, 'text') or not response.text:
                print("Warning: No text in AI response")
                return "ã‚ã‹ã‚Šã¾ã—ãŸã€‚è©³ã—ããŠè©±ã‚’èã‹ã›ã¦ãã ã•ã„ã€‚"
            
            return response.text.strip()
            
        except Exception as e:
            print(f"AI Response Generation Error: {str(e)}")
            return "ã‚ã‹ã‚Šã¾ã—ãŸã€‚è©³ã—ããŠè©±ã‚’èã‹ã›ã¦ãã ã•ã„ã€‚"
